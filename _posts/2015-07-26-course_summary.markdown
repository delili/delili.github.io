---
author: admin
comments: true
date: 2015-07-26 16:04:52+00:00
layout: post
title: 研一下课程总结
categories:
- 学习
tags:
- 学习
---


***

研一的课程结束了，在这里记录一下。

- **《云计算技术及应用》**
   
前期老师普及了一下云计算相关概念，讲了一下最近很火的docker；接下来开始由同学讲论文，论文都来自于[cloudcom2014][1],我选的论文是"[TraceBench An Open Data Set for Trace-Oriented Monitoring][2]" ,一篇关于trace数据集生成及系统架构的文章，后面的应用部分由于没有相关的应用经验，读起来挺费劲的。
最后做了一个简单的综述报告，找了3篇trace系统相关的文章，对比分析了一下，不过只有15分钟，对文章并没有精读。   
值得一提的是，老师最后请来了一位在google工作N年的师兄（现已回国创业）和一位来自IBM CRL的刚中了一篇sigmod的大牛来跟我们深入交流，收获颇丰。

 - **《软件工程前沿专题》**
   
软件所开的必修，由软件所各个组的老师或者博士生们来科普他们的工作，可以说涵盖软件工程领域的各个方面。老师们也都非常认真的给我们讲解，但有时候碰到自己不感兴趣的就不会认真去听了。最后听了李戈老师讲了他们在深度学习方面的成果，还是挺有意思的。      
大作业是写了一篇初步的综述，至少参考3篇顶会的文章，我选的方向是代码补全（code completion）。虽然只看了3篇文章，但也对这个小方向有了一定的了解，代码补全对提升开发人员的效率还是有很大帮助的，尤其是java开发。

 - **《文本挖掘技术》**
    
信科开的一门选修，课程内容涉及到文本挖掘的各个方面，但是老师讲的一般，也因此一共没去上几次课。   
两次作业也都不难。第一次作业是twitter检索，用的是TREC2012的一个数据集，因为是直接利用工具（Lemur)做，过程还算简单。结果优化上助教给了很多提示，最后做到MAP了0.3。比较有收获的地方就是知道了伪相关反馈以及后期和同学交流过程中了解到还可以利用查询扩展来提高准确度。   
第二次作业是Kaggle上的一个简单题目，利用Word2Vec进行电影评论分类。按部就班，按照教程的步骤完成了3次实验。最后大家的结果基本都是在[sweezyjeezy][3]的基础上进行调参得到的，因为TF-IDF+LR的效果惊人的好。

 - **《机器学习》**
   
计算语言所的课，因此作业都是文本NLP相关问题。老师讲得还行，只是总是自己在讲，缺乏互动了。也请老师原谅我对公式的推倒与被推倒部分没有用心听（其实是数学太差听不下去），只好自己去看看感兴趣的部分了。老师每次上课前都会把这次课的内容放到course上，还是很贴心的，可以让我提前决定这节课去不去上。   
一共三次作业，一次课堂测试。三次作业分别是关于评论情感分类、人名消歧和中文分词（或中文词性标注）的，作业代码放到[git][4]上了。   
这门课自己动手稍微多一些，理论上学到的比较少（太懒）。遗憾的是没能在这课上实践一下深度学习的方法。


学分已经修够了，不出意外应该不会再选其他课了。感谢各位任课老师的教导，学到了很多，无论是在理论上还是对待学习的态度上。


  [1]: http://2014.cloudcom.org/
  [2]: http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=7037711&punumber=7031670&sortType=asc_p_Sequence&filter=AND%28p_IS_Number:7036227%29&pageNumber=4
  [3]: https://www.kaggle.com/c/word2vec-nlp-tutorial/forums/t/11261/beat-the-benchmark-with-shallow-learning-0-95-lb    
  [4]: https://github.com/delili?tab=repositories  
